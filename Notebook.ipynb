{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erjon\\Documents\\2. HTW Berlin\\3. Courses\\2024 - 4\\Code\\thesis-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qa_model import answer_question\n",
    "from data_manager import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, questions_df, answers_df, model = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what are some neural network architectures that can give good results on the recommeder system?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_question, similar_questions, similar_answers, answer_content = answer_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am sure data science as will be discussed in this forum has several synonyms or at least related fields where large data is analyzed.\\n\\nMy particular question is in regards to Data Mining.  I took a graduate class in Data Mining a few years back.  What are the differences between Data Science and Data Mining and in particular what more would I need to look at to become proficient in Data Mining?\\n',\n",
       " 'I was wondering (about a more semantic question), is there a difference between data-driven methods and machine learning? Or is it more correct to state that machine learning is a category of data-driven methods (and what then are other categories)? \\n',\n",
       " \"When ever the word data science pops up people generally become quick to move to machine learning. Is that the right thing? For a data scientist isn't the handling of data (collection, pre-processing, visualization, etc.,) more important?\\nI am aware of the thread What is valued more in the data science job market, statistical analysis or data processing?, but the answers really didn't help me and the job market has changed since then!\\n\",\n",
       " 'is there big difference between data Science , big Data and database? i am confused in these three can anyone help me to out of this confusion?\\n',\n",
       " 'I just started learning machine learning and learned a few basic algorithms and there is one stupid doubt in my mind and I am unable to find the answer of it. What do we actually study in machine learning algorithms that solves kinds of problems based on the data given to the algorithms?\\n\\nTake an example of linear regression:\\n\\n\\nWe give data.\\nWe tell machine how to calculate error.\\nUsing gradient descent also we are telling machine how to optimize and based on all above some optimized parameters come out.\\n\\n\\nWhy there is actually a \"learning\" word in this algorithm? Although we are the telling how to perform steps and we have provided all the mathematics in this algorithm.\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the information provided in the answers, data science encompasses a broader range of activities including data manipulation, communication, and working with messy data sets, while machine learning specifically focuses on developing algorithms to learn from data and make predictions. Data science involves applying mathematical and computer science algorithms to extract useful information from disordered data, while machine learning aims to find the best parameters for an equation to predict target values accurately. Therefore, data science is a multidisciplinary field that includes machine learning as one of its components.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_question(question):\n",
    "    words = question.split()\n",
    "    perturbed_questions = []\n",
    "    for i in range(len(words)):\n",
    "        new_question = words[:i] + words[i+1:]\n",
    "        perturbed_questions.append(' '.join(new_question))\n",
    "    return perturbed_questions\n",
    "\n",
    "# Original question\n",
    "original_question = \"How does the COVID-19 vaccine work?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['does the COVID-19 vaccine work?',\n",
       " 'How the COVID-19 vaccine work?',\n",
       " 'How does COVID-19 vaccine work?',\n",
       " 'How does the vaccine work?',\n",
       " 'How does the COVID-19 work?',\n",
       " 'How does the COVID-19 vaccine']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturb_question(original_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df_test = questions_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "def convert_embedding(str_embedding):\n",
    "    # Remove brackets and split the string by spaces\n",
    "    str_embedding = str_embedding.strip(\"[]\")\n",
    "    # Split the string into a list of strings, each representing a float\n",
    "    list_of_strings = str_embedding.split()\n",
    "    # Convert each string in the list to a float and create a numpy array\n",
    "    return np.array([float(x) for x in list_of_strings], dtype=np.float32)\n",
    "\n",
    "embeddings_matrix = np.array([convert_embedding(e) for e in questions_df['embedding'].astype(str).values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faiss import normalize_L2\n",
    "\n",
    "d = embeddings_matrix.shape[1]\n",
    "index = faiss.IndexFlatIP(d)\n",
    "normalize_L2(embeddings_matrix)\n",
    "index.add(embeddings_matrix)\n",
    "\n",
    "index_selection = 'cos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "index = faiss.read_index(\"data/cosine_index.faiss\")\n",
    "questions_df = pd.read_csv('data/questions.csv', index_col='Id')\n",
    "answers_df = pd.read_csv('data/answers.csv', index_col='Id')\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question1(new_question, n=5, index=index, questions=questions_df, answers=answers_df, model=model):\n",
    "    # Encode the question to get its embedding, ensuring it's in the correct shape\n",
    "    \n",
    "\n",
    "    # Encode the question to get its embedding, ensuring it's in the correct shape\n",
    "    question_embedding = model.encode([new_question]).reshape(1, -1)\n",
    "    #faiss.normalize_L2(question_embedding.reshape(1, -1))\n",
    "    # Search the index for the n closest questions by inner product\n",
    "    D, I = index.search(question_embedding, n)        \n",
    "    # get the similarity score of the closest question\n",
    "    question_ids = questions.iloc[I[0]].index\n",
    "    distance_normalized = D\n",
    "    \n",
    "    # Prepare lists to hold the similar questions and their answers\n",
    "    similar_questions = []\n",
    "    similar_answers = pd.DataFrame()\n",
    "    \n",
    "    # Loop through each similar question ID to get the question text and its answers\n",
    "    for q_id in question_ids:\n",
    "        similar_questions.append(questions.loc[q_id].Body)  # Assuming there's a QuestionText column\n",
    "        q_answers = answers[answers['ParentId'] == q_id]\n",
    "        similar_answers = pd.concat([similar_answers, q_answers], ignore_index=True)\n",
    "\n",
    "    \n",
    "    content = f\"I have a question that I need answered based solely on the information contained in the following 5 answers. Please do not use any external knowledge or pre-existing information you might have. Just use the details provided in these answers to formulate the best possible response. If the answer is not in the provided information, answer that you dont have enough information to provide an answer. Be coincise.\\n\\n\\n\"\n",
    "\n",
    "\n",
    "    for i, answer in enumerate(similar_answers['Body']): # Assumes a list of answers\n",
    "        content += f\"Start of Answer {i+1}: {answer}\\n End of Answer {i+1}\\n\\n\\n\"      \n",
    "    content += f\"Question: {new_question}\"\n",
    "    client = OpenAI(api_key=chatgpt_key)\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": content,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.0,\n",
    "        max_tokens=150,\n",
    "    )\n",
    "\n",
    "    answer_content = chat_completion.choices[0].message.content\n",
    "\n",
    "    return new_question, similar_questions, similar_answers, answer_content, distance_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_question, similar_questions, similar_answers, answer_content, similarity = answer_question1(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are some neural network architectures that can give good results on the recommeder system?'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When I first read about neural networks, I learned that Backpropagation is the algorithm used to train the neural network. I am interested if there are other alternatives (or better?) to BP. \\n\\nWhat are the other training algorithms used in NN? And is BP is the best one, and that's why almost everyone uses it for training the NN model?\\n\",\n",
       " 'What are the best machine learning techniques to classify responders to a medicine if I have:\\n\\n\\nClinical data with ~200 features (age, education, marital status etc.)\\nGene data with around 250K features (genom data (snips) taken from the patient (DNA analysis))\\nNumber of obs. ~ 4K (the data is taken from a study on 4000 patients).\\n\\n\\nPlease advise.\\n',\n",
       " \"Disclaimer: I am almost a complete novice when it comes to tensorflow, keras, coding in general, and neural networks/data science.\\nWhile reading papers on novel architectures for neural nets, I see diagrams and such describing their ideas, and then they present their results, with no code shown. While learning to apply neural nets, I just load in the data, build a model by stacking layers like LSTM, Dense, etc, and training it. In other words I can't see how to do anything that isn't straight out of the box.\\nWhat tools, libraries, etc, do researchers use to implement these architectures when the layers aren't as simple as model.add(Dense(1))\\nFor example, how might we implement the SeqMO algorithm described in this paper?\\nhttps://arxiv.org/pdf/1806.05357.pdf\\n\",\n",
       " 'So I have looked at some of the literature on neural networks and read some chapters, but the learning curve is so steep that I have had trouble even getting started on designing the neural network to solve my problem.\\n\\nFrom what I understand, the architecture (or arrangement of neurons and their connections) should be designed according to the nature of the problem to be solved. Other parameters to be set according to the nature of the problem include the loss index (how the error will be calculated and if there should be a regularization term), whether or not there should be any scaling/unscaling, bounding, or conditions, and the training algorithm (such as the quasi-Newton method).\\n\\nThe particular type of problem I am interested in is using neural networks to figure out unknown functions (with unknown complexity) that input and output integers (as opposed to continuous values), given a large collection of inputs and outputs.\\n\\n\\n  An example function takes 4 byte inputs and returns 2 byte outputs. This is done by first taking the first 2 bytes of input and XORing them with the last 2 bytes, to produce an intermediate result. This two byte value is then XORed with a copy of itself that is shifted left by 5 bits. This result is then XORed with a copy of itself shifted right by 7 bits. Then this result is then XORed with a copy of itself shifted left by 2 bits, and this value is outputted by the function, giving the final 2-byte result. Note: More than one unique input can produce the same output.\\n\\n\\nSo given a large set of inputs and outputs of an unknown function, the neural network should then optimize itself to reproduce this function given new inputs. I am not sure how to get started designing this neural network, and I am not sure fully reading through neural networks textbooks is the optimal way to get started. I am using a software library meant for designing neural networks, and I can simply set the network architecture and the parameters described above. How much theory do I need to know in order to get started solving my problem? Where should I start with learning how to design this neural network?\\n\\nEDIT:\\nThe main goal of all this is to use an existing tool to simplify producing an output (a 2-byte code, in the example above) given a new input, in a situation where the function is unknown. Neural networks seem to match the function-finding-through-trial-and-error characteristics that I need. This tool should be able to try all sorts of possible functions of increasing complexities in order to mimic the working of the actual unknown function.\\n',\n",
       " 'I have a basic question about choosing right architecture of my deep learning task.\\n\\nI have input signal $X(t)$ as a function of time when it is fed to the system, it generates output $Y(t)$ which is also a function of time.\\n\\nI have a bunch of experiments performed with many input signals $X_1, X_2, X_3 ,...$ and many output signals $Y_1,Y_2,Y_3,...$.\\n\\nInstead of performing more experiments I would like to generate neural net where I can feed input signal X (t) and get output Y (t). \\nI want to use already measured data as training data. \\n\\nTo me, this looks like like regression problem but involves time series data.\\nOne of the neural network architectures that come to mind is RNN LSTM OR CNN.\\nPeople mainly use LSTM for forecasting problem (knowing history to predict the future) not regression. \\n\\nSo can I use CNN, use 1D filters and then some pooling and fully connected layers?\\nWill this work? What kind of set up should I use?\\n']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the information provided in the answers, some neural network architectures that can potentially give good results on a recommender system include feedback-alignment (FA), Direct Feedback Alignment (DFA), Indirect Feedback Alignment (IFA), custom defined layers in Keras/TensorFlow, one-dimensional convolutions using tf.nn.conv1d in TensorFlow, and RNN networks like LSTMs and GRUs. However, the specific details on how these architectures are implemented and their effectiveness in recommender systems are not explicitly mentioned in the provided information.'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56415224, 0.5240064 , 0.5211463 , 0.5211413 , 0.51799667]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
